"""
Script principal pour entraÃ®ner, Ã©valuer et visualiser les agents GridWorld
"""

import subprocess
import sys
import os
import argparse


def run_command(command, description):
    """ExÃ©cuter une commande avec affichage"""
    print(f"\n{'='*70}")
    print(f"  {description}")
    print(f"{'='*70}\n")
    
    result = subprocess.run(command, shell=True)
    if result.returncode != 0:
        print(f"\nâš ï¸  Erreur lors de: {description}")
        sys.exit(1)
    print(f"\nâœ“ {description} - TerminÃ© avec succÃ¨s")


def main():
    parser = argparse.ArgumentParser(
        description='Pipeline complet d\'entraÃ®nement GridWorld RL',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples d'utilisation:

1. EntraÃ®ner PPO sur GridWorld simple:
   python run_all.py --algo ppo --env GridWorld-Simple-v0 --timesteps 100000

2. EntraÃ®ner DQN sur goals mobiles et visualiser:
   python run_all.py --algo dqn --env GridWorld-MovingGoals-v0 --timesteps 200000 --visualize

3. Tout exÃ©cuter (entraÃ®ner, Ã©valuer, visualiser):
   python run_all.py --algo ppo --env GridWorld-Simple-v0 --all

4. Seulement Ã©valuer un modÃ¨le existant:
   python run_all.py --eval_only --model ./models/ppo_GridWorld-Simple-v0_final --algo ppo --env GridWorld-Simple-v0
        """
    )
    
    # Arguments principaux
    parser.add_argument('--algo', type=str, default='ppo', 
                        choices=['ppo', 'dqn'],
                        help='Algorithme RL (ppo ou dqn)')
    parser.add_argument('--env', type=str, default='GridWorld-Simple-v0',
                        choices=['GridWorld-Simple-v0', 'GridWorld-MovingGoals-v0',
                                'GridWorld-MovingObstacles-v0', 'GridWorld-FullDynamic-v0'],
                        help='Environnement GridWorld')
    
    # Options d'entraÃ®nement
    parser.add_argument('--timesteps', type=int, default=100000,
                        help='Nombre de timesteps d\'entraÃ®nement')
    parser.add_argument('--n_envs', type=int, default=4,
                        help='Nombre d\'environnements parallÃ¨les (PPO)')
    
    # Options d'Ã©valuation
    parser.add_argument('--eval_episodes', type=int, default=10,
                        help='Nombre d\'Ã©pisodes d\'Ã©valuation')
    parser.add_argument('--eval_delay', type=float, default=0.3,
                        help='DÃ©lai entre steps lors de l\'Ã©valuation')
    
    # Options de workflow
    parser.add_argument('--train_only', action='store_true',
                        help='Seulement entraÃ®ner')
    parser.add_argument('--eval_only', action='store_true',
                        help='Seulement Ã©valuer (nÃ©cessite --model)')
    parser.add_argument('--model', type=str,
                        help='Chemin vers le modÃ¨le (pour eval_only)')
    parser.add_argument('--visualize', action='store_true',
                        help='CrÃ©er les graphiques de visualisation')
    parser.add_argument('--all', action='store_true',
                        help='Tout exÃ©cuter: entraÃ®ner + Ã©valuer + visualiser')
    
    # Chemins
    parser.add_argument('--save_path', type=str, default='./models',
                        help='Chemin de sauvegarde des modÃ¨les')
    parser.add_argument('--plot_path', type=str, default='./plots',
                        help='Chemin de sauvegarde des graphiques')
    
    args = parser.parse_args()
    
    # DÃ©terminer le workflow
    if args.all:
        do_train = True
        do_eval = True
        do_viz = True
    elif args.train_only:
        do_train = True
        do_eval = False
        do_viz = False
    elif args.eval_only:
        if not args.model:
            print("âŒ Erreur: --model est requis avec --eval_only")
            sys.exit(1)
        do_train = False
        do_eval = True
        do_viz = False
    else:
        # Par dÃ©faut: entraÃ®ner et Ã©valuer
        do_train = True
        do_eval = True
        do_viz = args.visualize
    
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘            PIPELINE GRIDWORLD RL - STABLE-BASELINES3              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Configuration:
  â€¢ Algorithme: {args.algo.upper()}
  â€¢ Environnement: {args.env}
  â€¢ Timesteps: {args.timesteps:,}
  â€¢ Ã‰pisodes d'Ã©valuation: {args.eval_episodes}

Workflow:
  â€¢ EntraÃ®nement: {'âœ“' if do_train else 'âœ—'}
  â€¢ Ã‰valuation: {'âœ“' if do_eval else 'âœ—'}
  â€¢ Visualisation: {'âœ“' if do_viz else 'âœ—'}
    """)
    
    # 1. ENTRAÃNEMENT
    if do_train:
        train_cmd = (
            f"python train.py "
            f"--algo {args.algo} "
            f"--env {args.env} "
            f"--timesteps {args.timesteps} "
            f"--n_envs {args.n_envs} "
            f"--save_path {args.save_path}"
        )
        run_command(train_cmd, f"EntraÃ®nement {args.algo.upper()} sur {args.env}")
        
        # DÃ©finir le chemin du modÃ¨le
        model_path = f"{args.save_path}/{args.algo}_{args.env}_final"
    else:
        model_path = args.model
    
    # 2. Ã‰VALUATION
    if do_eval:
        eval_cmd = (
            f"python evaluate.py "
            f"--model {model_path} "
            f"--algo {args.algo} "
            f"--env {args.env} "
            f"--episodes {args.eval_episodes} "
            f"--delay {args.eval_delay}"
        )
        run_command(eval_cmd, f"Ã‰valuation du modÃ¨le sur {args.eval_episodes} Ã©pisodes")
    
    # 3. VISUALISATION
    if do_viz:
        viz_cmd = (
            f"python visualize_training.py "
            f"--log_dir {args.save_path}/logs "
            f"--save_path {args.plot_path} "
            f"--smooth 0.9"
        )
        run_command(viz_cmd, "CrÃ©ation des graphiques de visualisation")
    
    # RÃ©sumÃ© final
    print(f"\n{'='*70}")
    print("  âœ“ PIPELINE TERMINÃ‰ AVEC SUCCÃˆS")
    print(f"{'='*70}\n")
    
    if do_train:
        print(f"ğŸ“ ModÃ¨le sauvegardÃ©: {model_path}")
        print(f"ğŸ“ Logs TensorBoard: {args.save_path}/logs")
        print(f"\nğŸ’¡ Pour visualiser avec TensorBoard:")
        print(f"   tensorboard --logdir {args.save_path}/logs\n")
    
    if do_viz:
        print(f"ğŸ“Š Graphiques sauvegardÃ©s dans: {args.plot_path}/")
    
    print("\nğŸ® Commandes utiles:")
    print(f"   â€¢ RÃ©-Ã©valuer: python evaluate.py --model {model_path} --algo {args.algo} --env {args.env}")
    print(f"   â€¢ Visualiser: python visualize_training.py --log_dir {args.save_path}/logs")
    print()


if __name__ == '__main__':
    main()


"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        EXEMPLES D'UTILISATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. ENTRAÃNEMENT COMPLET (PPO sur grille simple):
   python run_all.py --algo ppo --env GridWorld-Simple-v0 --timesteps 100000 --all

2. ENTRAÃNEMENT COMPLET (DQN sur goals mobiles):
   python run_all.py --algo dqn --env GridWorld-MovingGoals-v0 --timesteps 200000 --all

3. ENTRAÃNEMENT LONG (environnement dynamique):
   python run_all.py --algo ppo --env GridWorld-FullDynamic-v0 --timesteps 300000 --n_envs 8 --all

4. SEULEMENT ENTRAÃNER:
   python run_all.py --algo ppo --env GridWorld-Simple-v0 --timesteps 100000 --train_only

5. Ã‰VALUER UN MODÃˆLE EXISTANT:
   python run_all.py --eval_only --model ./models/ppo_GridWorld-Simple-v0_final --algo ppo --env GridWorld-Simple-v0 --eval_episodes 20

6. ENTRAÃNER ET VISUALISER (sans Ã©valuation dÃ©taillÃ©e):
   python run_all.py --algo dqn --env GridWorld-MovingGoals-v0 --train_only --visualize

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""